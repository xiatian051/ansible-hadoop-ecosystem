<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- {{ ansible_managed }} -->
<configuration>

    <!-- namenode config -->
    <property>
        <name>dfs.nameservices</name>
        <value>{{ site_name|lower }}</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file://{{ hadoop['dfs_dir_parent'] }}{{ hadoop['dfs_dir_nn'] }}</value>
        <description>Determines where on the local filesystem the DFS name node should store the name table.If this is a comma-delimited list of directories,then name table is replicated in all of the directories,for redundancy.</description>
        <final>true</final>
    </property>


    <!-- HA start configuration, see http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/latest/PDF/CDH4-High-Availability-Guide.pdf -->
    <property>
        <name>dfs.ha.namenodes.{{ site_name|lower }}</name>
        <value>{% for host in groups['namenodes'] %}nn{{ loop.index }}{% if not loop.last %},{% endif %}{% endfor %}</value>
    </property>

    {% for host in groups['namenodes'] %}
    <property>
        <name>dfs.namenode.rpc-address.{{ site_name|lower }}.nn{{ loop.index }}</name>
        <value>{{ hostvars[host].ipv4_address}}:8020</value>
    </property>
    {% endfor %}

    {% for host in groups['namenodes'] %}
    <property>
        <name>dfs.namenode.http-address.{{ site_name|lower }}.nn{{ loop.index }}</name>
        <value>{{ hostvars[host].ipv4_address }}:50070</value>
    </property>
    {% endfor %}

    <!-- Storage for edits' files -->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://{% for host in groups['journalnodes'] %}{{ hostvars[host].ipv4_address }}:8485{% if not loop.last %};{% endif %}{% endfor %}/{{ site_name|lower }}</value>
    </property>

    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>{{ hadoop['dfs_dir_parent'] }}{{ hadoop['dfs_dir_jn'] }}</value>
    </property>


    <!-- Client failover -->
    <property>
        <name>dfs.client.failover.proxy.provider.{{ site_name|lower }}</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>


    <!-- Automatic failover configuration -->
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>

    <property>
        <name>ha.zookeeper.quorum</name>
        <value>{% for host in groups['zookeepers'] %}{{ hostvars[host].ipv4_address }}:2181{% if not loop.last %},{% endif %}{% endfor %}</value>
    </property>

    <!-- HA end -->


    <!-- datanode config -->
    <property>
        <name>dfs.blocksize</name>
        <value>{{ dfs_blocksize }}</value>
        <final>true</final>
    </property>
    <property>
        <name>dfs.datanode.max.xcievers</name>
        <value>{{ max_xcievers }}</value>
        <final>true</final>
    </property>

    {% set flag=0 %}
    <property>
        <name>dfs.datatnode.data.dir</name>
        <value>{% for data_dir in hadoop['dfs_dir_dn'] %}{% if not loop.first and flag == 1 %},{% else %}{% set flag=1 %}{% endif %}file://{{ hadoop['dfs_dir_parent'] }}{{ data_dir }}{% endfor %}</value>
    </property>

    <property>
        <name>dfs.hosts.exclude</name>
        <value>{{ service_dir }}/hadoop-{{ hadoop_version }}/etc/hadoop/excludes</value>
        <description>Names a file that contains a list of hosts that are
            not permitted to connect to the namenode.  The full pathname of the
            file must be specified.  If the value is empty, no hosts are
            excluded.</description>
    </property>

    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>

    <property>
        <name>dfs.namenode.handler.count</name>
        <value>100</value>
        <description>More NameNode server threads to handle RPCs from large number of DataNodes</description>
    </property>
    <property>
        <name>dfs.datanode.max.transfer.threads</name>
        <value>4096</value>
    </property>
    <property>
        <name>dfs.datanode.balance.bandwidthPerSec</name>
        <value>31457280</value>
        <description>
            Specifies the maximum amount of bandwidth that each datanode
            can utilize for the balancing purpose in term of
            the number of bytes per second.
        </description>
    </property>

    <property>
        <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
        <value>true</value>
        <description>
            Boolean which enables backend datanode-side support for the experimental DistributedFileSystem#getFileVBlockStorageLocations API.
        </description>
    </property>
    <property>
        <name>dfs.datanode.du.reserved</name>
        <value>5368709120</value>
        <description>Reserved space in bytes per volume. Always leave this much space free for non dfs use.
        </description>
    </property>
    <property>
        <name>dfs.datanode.failed.volumes.tolerated</name>
        <value>0</value>
        <description></description>
    </property>
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>shell(/bin/true)</value>
    </property>
    <property>
        <name>dfs.ha.fencing.ssh.connect-timeout</name>
        <value>10000</value>
    </property>
    <property>
        <name>heartbeat.recheck.interval</name>
        <value>5000</value>
    </property>
    <property>
        <name>dfs.heartbeat.interval</name>
        <value>3</value>
        <description>Determines datanode heartbeat interval in seconds.</description>
    </property>
    <property>
        <name>dfs.datanode.socket.write.timeout</name>
        <value>100000000</value>
    </property>
    <property>
        <name>dfs.socket.timeout</name>
        <value>100000000</value>
    </property>
    <property>
        <name>dfs.client.socket-timeout</name>
        <value>300000</value>
        <description></description>
    </property>

    <!-- configurations for nnbench test -->
    <property>
        <name>dfs.namenode.fs-limits.min-block-size</name>
        <value>1</value>
        <description>Minimum block size in bytes, enforced by the Namenode at create
            time. This prevents the accidental creation of files with tiny block
            sizes (and thus many blocks), which can degrade
            performance.</description>
    </property>

    <property>
        <name>dfs.namenode.fs-limits.max-blocks-per-file</name>
        <value>1048576</value>
        <description>Maximum number of blocks per file, enforced by the Namenode on
            write. This prevents the creation of extremely large files which can
            degrade performance.</description>
    </property>

    <!-- namenode img config -->
    <property>
        <name>dfs.image.compress</name>
        <value>false</value>
        <description>Should the dfs image be compressed?
        </description>
    </property>

    <property>
        <name>dfs.image.compression.codec</name>
        <value>org.apache.hadoop.io.compress.SnappyCodec</value>
        <description>If the dfs image is compressed, how should they be compressed?
            This has to be a codec defined in io.compression.codecs.
        </description>
    </property>

    <property>
        <name>dfs.image.transfer.timeout</name>
        <value>60000</value>
        <description>
            Socket timeout for image transfer in milliseconds. This timeout and the related
            dfs.image.transfer.bandwidthPerSec parameter should be configured such
            that normal image transfer can complete successfully.
            This timeout prevents client hangs when the sender fails during
            image transfer. This is socket timeout during image tranfer.
        </description>
    </property>

    <property>
        <name>dfs.image.transfer.bandwidthPerSec</name>
        <value>4194304</value>
        <description>
            Maximum bandwidth used for image transfer in bytes per second.
            This can help keep normal namenode operations responsive during
            checkpointing. The maximum bandwidth and timeout in
            dfs.image.transfer.timeout should be set such that normal image
            transfers can complete successfully.
            A default value of 0 indicates that throttling is disabled.
        </description>
    </property>

    <property>
        <name>dfs.image.transfer.chunksize</name>
        <value>65536</value>
        <description>
            Chunksize in bytes to upload the checkpoint.
            Chunked streaming is used to avoid internal buffering of contents
            of image file of huge size.
        </description>
    </property>

    <!-- security config -->
    <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.support.append</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.permission</name>
        <value>false</value>
    </property>
    <property>
        <name>dfs.permissions.enabled</name>
        <value>false</value>
        <description>
            If "true", enable permission checking in HDFS.
            If "false", permission checking is turned off,
            but all other behavior is unchanged.
            Switching from one parameter value to the other does not change the mode,
            owner or group of files or directories.
        </description>
    </property>
    <property>
        <name>dfs.namenode.acls.enabled</name>
        <value>false</value>
        <description>
            Set to true to enable support for HDFS ACLs (Access Control Lists).  By
            default, ACLs are disabled.  When ACLs are disabled, the NameNode rejects
            all RPCs related to setting or getting ACLs.
        </description>
    </property>

</configuration>
